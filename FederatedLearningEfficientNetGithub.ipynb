{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8a6da-5648-463c-906f-7172b56d1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, Xception\n",
    "import efficientnet.keras as efn\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Image parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "# Placeholder dataset paths for five clients\n",
    "# Replace these with actual paths or generators for the respective clients\n",
    "train_generators = [None] * 5  # Replace with actual generators for 5 clients' training data\n",
    "validation_generators = [None] * 5  # Replace with actual generators for 5 clients' validation data\n",
    "\n",
    "# Number of classes from training data (manually set, or derived from actual data)\n",
    "num_output_classes = 2  # Set to the correct number of output classes for your task\n",
    "\n",
    "# SimpleModel class definition\n",
    "class TransferLearningModel:\n",
    "    def build(self):\n",
    "        base_model = efn.EfficientNetB7(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "        transfer_layer = base_model.get_layer('top_activation')\n",
    "        conv_model = Model(inputs=base_model.input, outputs=transfer_layer.output)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(conv_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(Dense(num_output_classes, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "# Learning rate schedule and optimizer\n",
    "learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = Adam(learning_rate=learning_rate_schedule)\n",
    "loss_function = 'categorical_crossentropy'\n",
    "evaluation_metrics = ['categorical_accuracy']\n",
    "\n",
    "# Build and compile the global model (used for initializing local models in each round)\n",
    "transfer_model = TransferLearningModel()\n",
    "global_model = transfer_model.build()\n",
    "global_model.compile(optimizer=optimizer, loss=loss_function, metrics=evaluation_metrics)\n",
    "\n",
    "# Placeholder test data generator (replace with actual test data)\n",
    "test_generator = None  # You need to create a test generator for actual data\n",
    "\n",
    "# Initial global model prediction (requires actual test data)\n",
    "# Uncomment this when you have a valid test generator\n",
    "# global_model.predict(test_generator)\n",
    "\n",
    "# Federated learning helper functions\n",
    "def scale_model_weights(weights, scale_factor):\n",
    "    return [scale_factor * weight for weight in weights]\n",
    "\n",
    "def aggregate_scaled_weights(scaled_weights):\n",
    "    return [tf.reduce_sum(weight, axis=0) for weight in zip(*scaled_weights)]\n",
    "\n",
    "# Incremental learning for Federated learning process for 5 clients\n",
    "num_comm_rounds = 60\n",
    "for round_num in range(num_comm_rounds):\n",
    "    global_weights = global_model.get_weights()  # Get global weights before each round\n",
    "    scaled_weights_per_client = []\n",
    "\n",
    "    for client_idx in range(5):  # Loop over 5 clients\n",
    "        local_model = transfer_model.build()  # Rebuild the local model for each client\n",
    "        local_model.compile(optimizer=optimizer, loss=loss_function, metrics=evaluation_metrics)\n",
    "        local_model.set_weights(global_weights)  # Initialize with global model weights\n",
    "        \n",
    "        # Placeholder steps, replace with actual steps_per_epoch based on your data\n",
    "        train_steps = 100  # Replace with actual steps per epoch for the client's data\n",
    "        validation_steps = 20  # Replace with actual validation steps for the client's data\n",
    "\n",
    "        # Incremental learning (train on new data and retain previously learned weights)\n",
    "        local_model.fit(\n",
    "            train_generators[client_idx],  # Training data for this client\n",
    "            epochs=1,\n",
    "            steps_per_epoch=train_steps,\n",
    "            validation_data=validation_generators[client_idx],  # Validation data for this client\n",
    "            validation_steps=validation_steps\n",
    "        )\n",
    "\n",
    "        # Scale and collect weights from this client\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), 1 / 5)  # 1/5 for 5 clients\n",
    "        scaled_weights_per_client.append(scaled_weights)\n",
    "\n",
    "    # Update global model weights with the averaged weights from 5 clients\n",
    "    averaged_weights = aggregate_scaled_weights(scaled_weights_per_client)\n",
    "    global_model.set_weights(averaged_weights)\n",
    "\n",
    "    # Simulate evaluation on test data (requires actual test data)\n",
    "    if test_generator is not None:\n",
    "        test_scores = global_model.evaluate(test_generator)\n",
    "        print(f\"Communication round {round_num}: Accuracy = {test_scores[1] * 100:.2f}%\")\n",
    "\n",
    "# Final prediction after training (requires actual test data)\n",
    "# Uncomment this when you have a valid test generator\n",
    "# predictions = global_model.predict(test_generator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
